{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural network -\n",
    "\n",
    "Basic neural network contains :\n",
    "* Input layer - this layer takes in the iput data but should formated in a way such that machine can understand . If text it has to tokenized (text to numbers ) , size depends upon number of feature, for pics it is pixel which depends.\n",
    "\n",
    "* Hidden layer - These are the layers which are connected to i/p layer and is called hidden because , machine has control over these layers . As in weights and bias are adjuseted accordingly.\n",
    "\n",
    "* Output Layer -  the ouput layer depend upon the type to type of result we want. Eg - in classification of sentiments , 2 layer o/p i.e negative or positive, or in pics differentiating cats and dogs etc etc..\n",
    "\n",
    "![Image of Neural network](https://databricks.com/wp-content/uploads/2019/02/neural1.jpg)\n",
    "\n",
    "## Single Neuron-\n",
    "* Sum of inputs if other neurons are connected , if i/p layer the i/p is the data . if its a hidden layer i/p's would be sum of o/p of other neurons.\n",
    "* [I/P * WEIGHT + BIAS] summed together\n",
    "* activation function - acts as firing , converting linear o/p to non linear . eg - stepper function , sigmoid , relu etc etc \n",
    "\n",
    "## Training neural network\n",
    "* passing in the input data and adjusting its weights and bias acrross all the neural such that it can predict the ouput .\n",
    "* it take million of data with many variables which is runned in epoches (loops in neural network) which makes a model mature enough to work efficiently .\n",
    "\n",
    "\n",
    "## What is pytorch ?\n",
    "* pytorch is numpy on GPU , thats it \n",
    "* has inbuilt function which contains many modules which can help build neural networks easily\n",
    "\n",
    "## What is a tensor ?\n",
    "* It is a array \n",
    "* maybe multi dimension array\n",
    "* & using tensors we can put this in GPU, which helps calculating weights and biases much faster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import library:\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5526e-01, 8.9394e-01, 5.4234e-04, 9.4524e-01, 5.1952e-01],\n",
      "        [9.5345e-01, 8.1685e-01, 1.9593e-01, 9.5136e-01, 2.8721e-01]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand([2,5]) ## We get random initialisation of 2,5 \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5526e-01, 8.9394e-01, 5.4234e-04, 9.4524e-01, 5.1952e-01, 9.5345e-01,\n",
       "         8.1685e-01, 1.9593e-01, 9.5136e-01, 2.8721e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REshaping tensor : OR Basically flatten\n",
    "# basically converting 2 x 5 i/p to single dimension or flattened i.e 1 x 10 \n",
    "\n",
    "y = y.view([1,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "\n",
    "We would be using torchvision dataset MNIST images dataset.\n",
    "\n",
    "MNIST is a hand drawn digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train = datasets.FashionMNIST(\"\",train=True,download=True,transform = transforms.Compose([transforms.ToTensor()])) \n",
    "# ## We are transforing it to tensor directly\n",
    "\n",
    "# test = datasets.FashionMNIST(\"\",train=False,download=True,\n",
    "#                              transform = transforms.Compose([transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%/Users/ajarpanwar/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\",train=True,download=True,transform = transforms.Compose([transforms.ToTensor()])) \n",
    "## We are transforing it to tensor directly\n",
    "\n",
    "test = datasets.MNIST(\"\",train=False,download=True,\n",
    "                             transform = transforms.Compose([transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: \n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: \n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Batch** = batch is nothing but data feed in groups , eg 100 row data can be fed in 10 batches i.e 10 shuffeled rows data per time\n",
    "* This whole operation can be done using dataloader func in pytorch in utils.data\n",
    "* Dataloader helps prepare torch data in a way that is understandable by nn, & can be fed to GPU\n",
    "* If we feed all data at once , model will overfit \n",
    "* Usally the batch size vary from 8 to 64 , but mainly depends upon RAM, size is not fixed rule but it depends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train,batch_size =10,shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(test,batch_size =10,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([6, 8, 2, 3, 4, 6, 7, 0, 7, 1])]\n"
     ]
    }
   ],
   "source": [
    "## for iterating through dataloader. this data contains a single batch\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "## Thus this is how the tensor converts the data of 28 x 28 image\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1258ce8d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(data[0][0]) # printing this would show an error due to the shape thus we have to flaten it\n",
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num': 0, 'count': 1}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "dic['num'] = 0\n",
    "dic['count'] = 1\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "total = 0\n",
    "for data in trainset:\n",
    "    x,y = data\n",
    "    for label in y:\n",
    "        dic[int(label)]+=1\n",
    "        total +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in dic:\n",
    "    print(f'{i}: {(dic[i]/total)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*thus data is almost balanced which for each class it is almost 10 %*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simple neural network is a feed forward neural network where data passes in one direction:\n",
    "* Here we are modifying simple neural network by adding activation function, which keeps numbers between a range & helps neurin in firing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn ## We have to initialise this\n",
    "import torch.nn.functional as F ## Here we have to pass parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() ## We are inherting the features of nn module\n",
    "        self.fc1 = nn.Linear(28*28,64) ## flatten 28*28 i.e feature as input and output can anything\n",
    "        self.fc2 = nn.Linear(64,80) # hidden layer 1 , output can be anythin we want, but input is output of fc1\n",
    "        self.fc3 = nn.Linear(80,64) # hidden layer 2 , output can be anythin we want\n",
    "        self.fc4 = nn.Linear(64,10) ## here 10 is the ouput as we 10 digits\n",
    "   \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=80, bias=True)\n",
      "  (fc3): Linear(in_features=80, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand([28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3196, 0.1044, 0.1343, 0.9877, 0.5658, 0.8307, 0.5631, 0.6815, 0.4484,\n",
       "         0.7630, 0.4981, 0.1778, 0.3754, 0.0376, 0.4803, 0.8559, 0.3461, 0.2577,\n",
       "         0.7660, 0.6704, 0.7199, 0.0253, 0.5073, 0.5351, 0.6584, 0.3951, 0.7941,\n",
       "         0.0486, 0.0640, 0.4856, 0.0938, 0.5871, 0.7029, 0.0991, 0.5567, 0.8527,\n",
       "         0.6369, 0.9197, 0.1024, 0.5484, 0.5431, 0.5729, 0.9824, 0.4559, 0.0586,\n",
       "         0.4568, 0.0674, 0.4204, 0.8517, 0.3370, 0.9793, 0.4235, 0.1975, 0.6294,\n",
       "         0.7656, 0.6795, 0.6139, 0.5657, 0.8225, 0.9148, 0.0739, 0.3808, 0.0248,\n",
       "         0.0314, 0.6358, 0.3227, 0.0708, 0.3384, 0.9111, 0.3742, 0.8265, 0.9026,\n",
       "         0.8205, 0.2537, 0.1400, 0.1579, 0.1709, 0.8375, 0.7153, 0.2749, 0.1617,\n",
       "         0.2532, 0.2162, 0.8264, 0.4762, 0.4046, 0.4998, 0.5064, 0.7134, 0.2963,\n",
       "         0.7659, 0.6266, 0.5406, 0.9597, 0.7047, 0.5794, 0.1694, 0.4205, 0.5571,\n",
       "         0.3453, 0.0350, 0.3924, 0.5391, 0.3124, 0.3089, 0.9990, 0.4295, 0.5423,\n",
       "         0.0870, 0.9308, 0.7040, 0.2313, 0.0685, 0.2148, 0.4338, 0.1473, 0.5722,\n",
       "         0.3851, 0.8555, 0.3950, 0.5520, 0.3777, 0.8731, 0.5372, 0.1713, 0.5314,\n",
       "         0.4298, 0.7404, 0.3347, 0.7815, 0.4277, 0.3637, 0.5158, 0.8081, 0.9172,\n",
       "         0.9124, 0.6304, 0.2985, 0.5171, 0.1358, 0.8887, 0.2698, 0.0039, 0.6556,\n",
       "         0.7813, 0.3525, 0.1038, 0.2709, 0.1322, 0.0421, 0.2388, 0.8194, 0.4731,\n",
       "         0.7803, 0.4172, 0.1901, 0.9901, 0.1653, 0.3971, 0.2312, 0.6839, 0.9071,\n",
       "         0.2600, 0.9160, 0.0318, 0.1483, 0.9032, 0.6205, 0.2412, 0.9672, 0.4259,\n",
       "         0.8900, 0.5115, 0.7442, 0.2501, 0.2050, 0.0717, 0.2215, 0.3428, 0.6017,\n",
       "         0.3960, 0.6341, 0.8773, 0.9044, 0.7899, 0.7567, 0.9685, 0.1494, 0.6038,\n",
       "         0.2538, 0.9226, 0.8292, 0.9393, 0.8089, 0.8271, 0.6538, 0.9555, 0.4908,\n",
       "         0.6578, 0.2272, 0.6820, 0.3348, 0.6910, 0.6475, 0.3694, 0.0421, 0.7240,\n",
       "         0.6509, 0.4399, 0.3385, 0.2125, 0.4638, 0.4272, 0.5364, 0.9759, 0.6162,\n",
       "         0.1717, 0.9973, 0.7323, 0.8332, 0.8463, 0.6638, 0.1733, 0.2491, 0.4345,\n",
       "         0.1082, 0.7306, 0.5475, 0.2754, 0.1964, 0.1508, 0.3109, 0.0105, 0.2930,\n",
       "         0.2156, 0.9824, 0.7062, 0.8229, 0.4916, 0.6960, 0.9231, 0.6322, 0.6161,\n",
       "         0.2031, 0.5374, 0.4873, 0.0973, 0.6692, 0.5787, 0.7282, 0.9219, 0.6309,\n",
       "         0.4986, 0.7957, 0.1030, 0.3772, 0.2089, 0.4471, 0.7591, 0.1682, 0.2451,\n",
       "         0.9310, 0.8933, 0.1708, 0.8535, 0.0931, 0.8169, 0.6878, 0.3294, 0.0031,\n",
       "         0.2500, 0.3041, 0.3940, 0.9705, 0.2524, 0.7824, 0.7101, 0.7618, 0.4450,\n",
       "         0.8125, 0.8833, 0.6003, 0.3833, 0.3426, 0.2811, 0.4029, 0.6348, 0.8696,\n",
       "         0.6452, 0.2041, 0.3118, 0.8663, 0.7643, 0.4348, 0.2955, 0.4452, 0.9039,\n",
       "         0.0709, 0.5562, 0.0078, 0.6258, 0.3558, 0.7434, 0.7478, 0.0581, 0.8039,\n",
       "         0.1339, 0.3739, 0.2914, 0.4575, 0.5834, 0.7240, 0.9431, 0.1288, 0.8854,\n",
       "         0.2072, 0.2308, 0.8095, 0.4152, 0.1642, 0.2305, 0.4493, 0.3412, 0.2187,\n",
       "         0.5682, 0.8669, 0.2674, 0.9853, 0.4808, 0.5278, 0.7560, 0.4284, 0.1408,\n",
       "         0.1308, 0.8649, 0.5455, 0.4820, 0.3205, 0.1219, 0.9509, 0.5244, 0.1313,\n",
       "         0.4524, 0.0574, 0.9950, 0.1626, 0.4473, 0.0433, 0.0163, 0.4658, 0.5119,\n",
       "         0.7634, 0.0745, 0.4470, 0.8636, 0.3234, 0.0850, 0.7840, 0.4761, 0.1826,\n",
       "         0.0768, 0.4793, 0.1866, 0.2733, 0.7062, 0.2222, 0.4828, 0.7560, 0.2102,\n",
       "         0.3870, 0.8232, 0.1957, 0.5429, 0.2016, 0.5911, 0.3365, 0.5296, 0.0512,\n",
       "         0.5960, 0.1423, 0.5880, 0.2376, 0.2758, 0.5083, 0.8188, 0.3651, 0.1666,\n",
       "         0.9474, 0.8444, 0.5796, 0.1045, 0.5524, 0.6435, 0.7922, 0.2331, 0.8757,\n",
       "         0.2460, 0.5716, 0.1839, 0.9150, 0.2505, 0.4057, 0.9519, 0.8846, 0.9724,\n",
       "         0.6240, 0.4524, 0.7370, 0.0176, 0.1114, 0.9053, 0.8762, 0.8817, 0.6429,\n",
       "         0.0673, 0.1785, 0.4331, 0.0085, 0.9233, 0.8499, 0.8848, 0.5878, 0.5086,\n",
       "         0.3022, 0.4332, 0.9250, 0.6881, 0.4158, 0.2344, 0.0545, 0.6759, 0.6632,\n",
       "         0.7449, 0.3913, 0.9412, 0.8757, 0.4079, 0.3575, 0.1150, 0.1938, 0.2216,\n",
       "         0.7497, 0.7243, 0.2423, 0.7243, 0.7490, 0.0215, 0.6228, 0.2144, 0.2520,\n",
       "         0.6591, 0.5738, 0.7425, 0.1957, 0.0067, 0.5544, 0.2232, 0.7049, 0.4719,\n",
       "         0.6252, 0.4865, 0.4618, 0.3141, 0.8995, 0.7877, 0.5128, 0.6556, 0.4690,\n",
       "         0.8495, 0.3433, 0.8659, 0.7621, 0.9453, 0.8739, 0.0278, 0.5413, 0.2634,\n",
       "         0.6245, 0.4899, 0.9579, 0.6743, 0.7447, 0.7883, 0.7575, 0.1141, 0.8248,\n",
       "         0.2197, 0.5472, 0.9785, 0.8025, 0.9786, 0.8352, 0.4905, 0.2113, 0.3256,\n",
       "         0.2098, 0.8442, 0.4964, 0.0127, 0.7289, 0.0907, 0.1407, 0.3761, 0.6496,\n",
       "         0.4423, 0.1514, 0.2233, 0.1987, 0.5383, 0.3893, 0.7973, 0.1264, 0.7113,\n",
       "         0.6899, 0.2988, 0.2361, 0.0944, 0.4308, 0.7960, 0.2540, 0.9439, 0.0561,\n",
       "         0.4444, 0.4672, 0.5258, 0.8663, 0.9482, 0.3254, 0.5649, 0.6990, 0.6116,\n",
       "         0.6641, 0.2420, 0.7221, 0.6811, 0.9373, 0.1363, 0.6802, 0.6284, 0.5535,\n",
       "         0.8439, 0.0271, 0.9767, 0.0210, 0.7215, 0.6626, 0.5800, 0.5655, 0.3448,\n",
       "         0.9801, 0.2846, 0.7758, 0.8986, 0.7615, 0.3893, 0.9084, 0.7775, 0.7063,\n",
       "         0.9502, 0.1483, 0.2849, 0.0114, 0.6873, 0.2205, 0.5186, 0.4720, 0.8411,\n",
       "         0.3857, 0.8840, 0.9813, 0.6702, 0.3320, 0.0989, 0.8285, 0.2321, 0.7107,\n",
       "         0.5105, 0.1179, 0.3176, 0.3083, 0.7604, 0.5793, 0.7068, 0.3923, 0.5616,\n",
       "         0.1880, 0.5787, 0.7024, 0.4819, 0.1228, 0.6197, 0.4098, 0.6524, 0.1001,\n",
       "         0.0567, 0.6849, 0.8080, 0.0737, 0.0277, 0.9335, 0.1163, 0.5780, 0.6488,\n",
       "         0.1918, 0.4594, 0.8158, 0.7432, 0.5925, 0.5772, 0.8883, 0.4205, 0.8044,\n",
       "         0.2590, 0.2153, 0.9835, 0.1829, 0.1848, 0.5006, 0.0980, 0.9436, 0.0432,\n",
       "         0.1970, 0.6007, 0.6822, 0.3259, 0.8479, 0.4194, 0.5979, 0.7092, 0.9038,\n",
       "         0.8163, 0.6326, 0.6901, 0.2329, 0.8582, 0.9988, 0.0386, 0.1151, 0.3769,\n",
       "         0.6059, 0.3505, 0.0942, 0.2905, 0.2414, 0.7191, 0.3521, 0.8698, 0.1247,\n",
       "         0.5569, 0.3626, 0.9199, 0.4028, 0.8093, 0.6853, 0.8448, 0.4810, 0.7935,\n",
       "         0.9101, 0.3744, 0.4636, 0.3511, 0.1177, 0.8807, 0.7087, 0.3480, 0.8133,\n",
       "         0.1660, 0.7556, 0.1475, 0.3761, 0.5918, 0.3344, 0.5696, 0.2414, 0.6225,\n",
       "         0.1569, 0.5382, 0.5676, 0.9032, 0.4865, 0.2578, 0.4226, 0.1340, 0.5453,\n",
       "         0.8749, 0.9072, 0.6173, 0.7696, 0.8454, 0.3829, 0.8634, 0.4943, 0.9295,\n",
       "         0.6116, 0.4678, 0.3077, 0.0665, 0.0386, 0.8066, 0.2237, 0.7007, 0.1663,\n",
       "         0.7339, 0.4269, 0.7384, 0.5039, 0.8835, 0.9687, 0.6588, 0.0049, 0.0322,\n",
       "         0.8000, 0.5381, 0.1981, 0.7608, 0.8396, 0.0567, 0.1057, 0.0486, 0.3652,\n",
       "         0.3134, 0.7717, 0.7854, 0.6551, 0.4272, 0.5677, 0.8872, 0.8093, 0.9279,\n",
       "         0.5554, 0.7095, 0.7851, 0.9366, 0.9478, 0.1739, 0.0812, 0.8237, 0.3947,\n",
       "         0.8029, 0.4293, 0.1559, 0.5654, 0.3606, 0.8862, 0.0379, 0.8694, 0.5236,\n",
       "         0.7031, 0.5896, 0.2240, 0.5625, 0.6238, 0.1991, 0.8687, 0.7457, 0.2046,\n",
       "         0.7540, 0.4302, 0.6071, 0.4541, 0.9695, 0.7337, 0.2611, 0.1853, 0.4453,\n",
       "         0.4044, 0.1201, 0.2807, 0.7338, 0.4779, 0.2069, 0.1092, 0.3027, 0.7869,\n",
       "         0.6272, 0.1569, 0.4311, 0.7982, 0.2134, 0.3014, 0.4225, 0.1411, 0.8784,\n",
       "         0.7914]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.view(1,28*28) ## 1 is specified because input will be of unkown shape as its shape is 1 by 28*28\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We feed this data to model \n",
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3456, -2.2506, -2.2979, -2.3358, -2.3908, -2.2394, -2.3405, -2.3646,\n",
       "         -2.2763, -2.2012]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is the actual prediction \n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss :\n",
    "\n",
    "How is the model predicting the values we want to predict \n",
    "\n",
    "## Learning Rate :\n",
    "    - Learning rate determines the size of the setp our model needs to take to make loss as minimum as possible\n",
    "    - If we make learning rate huge , it will take huge steps and will never get to the point of minima \n",
    "    - Hence we specify lower rate so as to it sticks to a lower point\n",
    "    - Loss function is added to calculate the liss , there are many ways , one hot vectors  - MSE , singular values we have to use NLL loss etc. Know which loss is applicabe to which environment.\n",
    "    \n",
    "## Q . Know decaying learning rate ??\n",
    "\n",
    "\n",
    "## Optimizer\n",
    "\n",
    "Optimizer basically optimize model by adjusting the weights & biases in the network so as to minimise our loss . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0155, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr=0.001 )\n",
    "\n",
    "## Epoch isiteration we want to make for our model through our data \n",
    "\n",
    "EPOCHES = 3\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    for data in trainset:\n",
    "        X,y = data \n",
    "#         print(X[0])\n",
    "#         print(y[0])\n",
    "        net.zero_grad() #everytime we pass our data through our network we have to make gradient zero other it will add itself.'''\n",
    "        output = net(X.view(-1,28*28)) ## now we have the ouput we have to calc how wrong are we \n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward() ## back propagation\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.968\n"
     ]
    }
   ],
   "source": [
    "## lets check how are we performing , testing data:\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        \n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total+=1\n",
    "            \n",
    "print(\"Accuracy :\",round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual digit: 1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[1].view(28,28))\n",
    "plt.show()\n",
    "\n",
    "print(f'actual digit: {torch.argmax(net(X[1].view(1,784))[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
